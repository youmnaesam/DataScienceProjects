{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XgR9ftrHeCxz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.4.1).\n",
      "Data source import complete.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "import kagglehub\n",
    "notshrirang_spotify_million_song_dataset_path = kagglehub.dataset_download('notshrirang/spotify-million-song-dataset')\n",
    "\n",
    "print('Data source import complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-30T10:01:48.744515Z",
     "iopub.status.busy": "2026-01-30T10:01:48.744246Z",
     "iopub.status.idle": "2026-01-30T10:01:50.83904Z",
     "shell.execute_reply": "2026-01-30T10:01:50.838162Z",
     "shell.execute_reply.started": "2026-01-30T10:01:48.744493Z"
    },
    "id": "gXBregNteCx1",
    "outputId": "0bdaec13-3d82-47de-b260-1fc21769b5ff"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  artist                   song                                        link  \\\n",
      "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
      "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
      "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
      "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
      "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
      "\n",
      "                                                text  \n",
      "0  Look at her face, it's a wonderful face  \\r\\nA...  \n",
      "1  Take it easy with me, please  \\r\\nTouch me gen...  \n",
      "2  I'll never know why I had to go  \\r\\nWhy I had...  \n",
      "3  Making somebody happy is a question of give an...  \n",
      "4  Making somebody happy is a question of give an...  \n"
     ]
    }
   ],
   "source": [
    "csv_path = os.path.join(\n",
    "    notshrirang_spotify_million_song_dataset_path,\n",
    "    \"spotify_millsongdata.csv\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57645</th>\n",
       "      <td>Ziggy Marley</td>\n",
       "      <td>Good Old Days</td>\n",
       "      <td>/z/ziggy+marley/good+old+days_10198588.html</td>\n",
       "      <td>Irie days come on play  \\r\\nLet the angels fly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57646</th>\n",
       "      <td>Ziggy Marley</td>\n",
       "      <td>Hand To Mouth</td>\n",
       "      <td>/z/ziggy+marley/hand+to+mouth_20531167.html</td>\n",
       "      <td>Power to the workers  \\r\\nMore power  \\r\\nPowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57647</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Come With Me</td>\n",
       "      <td>/z/zwan/come+with+me_20148981.html</td>\n",
       "      <td>all you need  \\r\\nis something i'll believe  \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57648</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Desire</td>\n",
       "      <td>/z/zwan/desire_20148986.html</td>\n",
       "      <td>northern star  \\r\\nam i frightened  \\r\\nwhere ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57649</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Heartsong</td>\n",
       "      <td>/z/zwan/heartsong_20148991.html</td>\n",
       "      <td>come in  \\r\\nmake yourself at home  \\r\\ni'm a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57650 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist                   song  \\\n",
       "0              ABBA  Ahe's My Kind Of Girl   \n",
       "1              ABBA       Andante, Andante   \n",
       "2              ABBA         As Good As New   \n",
       "3              ABBA                   Bang   \n",
       "4              ABBA       Bang-A-Boomerang   \n",
       "...             ...                    ...   \n",
       "57645  Ziggy Marley          Good Old Days   \n",
       "57646  Ziggy Marley          Hand To Mouth   \n",
       "57647          Zwan           Come With Me   \n",
       "57648          Zwan                 Desire   \n",
       "57649          Zwan              Heartsong   \n",
       "\n",
       "                                              link  \\\n",
       "0       /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1            /a/abba/andante+andante_20002708.html   \n",
       "2             /a/abba/as+good+as+new_20003033.html   \n",
       "3                       /a/abba/bang_20598415.html   \n",
       "4           /a/abba/bang+a+boomerang_20002668.html   \n",
       "...                                            ...   \n",
       "57645  /z/ziggy+marley/good+old+days_10198588.html   \n",
       "57646  /z/ziggy+marley/hand+to+mouth_20531167.html   \n",
       "57647           /z/zwan/come+with+me_20148981.html   \n",
       "57648                 /z/zwan/desire_20148986.html   \n",
       "57649              /z/zwan/heartsong_20148991.html   \n",
       "\n",
       "                                                    text  \n",
       "0      Look at her face, it's a wonderful face  \\r\\nA...  \n",
       "1      Take it easy with me, please  \\r\\nTouch me gen...  \n",
       "2      I'll never know why I had to go  \\r\\nWhy I had...  \n",
       "3      Making somebody happy is a question of give an...  \n",
       "4      Making somebody happy is a question of give an...  \n",
       "...                                                  ...  \n",
       "57645  Irie days come on play  \\r\\nLet the angels fly...  \n",
       "57646  Power to the workers  \\r\\nMore power  \\r\\nPowe...  \n",
       "57647  all you need  \\r\\nis something i'll believe  \\...  \n",
       "57648  northern star  \\r\\nam i frightened  \\r\\nwhere ...  \n",
       "57649  come in  \\r\\nmake yourself at home  \\r\\ni'm a ...  \n",
       "\n",
       "[57650 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:01:50.840706Z",
     "iopub.status.busy": "2026-01-30T10:01:50.840344Z",
     "iopub.status.idle": "2026-01-30T10:01:52.419869Z",
     "shell.execute_reply": "2026-01-30T10:01:52.41899Z",
     "shell.execute_reply.started": "2026-01-30T10:01:50.840681Z"
    },
    "id": "BuuPfRkceCx2",
    "outputId": "a6a1ec2b-c951-4528-8c48-1ac03130d0b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pandas as pd\\n\\n# Replace with your actual file path\\ndf = pd.read_csv('/kaggle/input/spotify-million-song-dataset/spotify_millsongdata.csv')\\n\\n# Display the first few rows\\nprint(df.head())\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import pandas as pd\n",
    "\n",
    "# Replace with your actual file path\n",
    "df = pd.read_csv('/kaggle/input/spotify-million-song-dataset/spotify_millsongdata.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:01:52.42098Z",
     "iopub.status.busy": "2026-01-30T10:01:52.420705Z",
     "iopub.status.idle": "2026-01-30T10:01:52.442578Z",
     "shell.execute_reply": "2026-01-30T10:01:52.441769Z",
     "shell.execute_reply.started": "2026-01-30T10:01:52.420951Z"
    },
    "id": "8FlxfagZeCx2",
    "outputId": "aba383ee-e45a-4235-d95f-dcd67562b5f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57645</th>\n",
       "      <td>Ziggy Marley</td>\n",
       "      <td>Good Old Days</td>\n",
       "      <td>/z/ziggy+marley/good+old+days_10198588.html</td>\n",
       "      <td>Irie days come on play  \\r\\nLet the angels fly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57646</th>\n",
       "      <td>Ziggy Marley</td>\n",
       "      <td>Hand To Mouth</td>\n",
       "      <td>/z/ziggy+marley/hand+to+mouth_20531167.html</td>\n",
       "      <td>Power to the workers  \\r\\nMore power  \\r\\nPowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57647</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Come With Me</td>\n",
       "      <td>/z/zwan/come+with+me_20148981.html</td>\n",
       "      <td>all you need  \\r\\nis something i'll believe  \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57648</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Desire</td>\n",
       "      <td>/z/zwan/desire_20148986.html</td>\n",
       "      <td>northern star  \\r\\nam i frightened  \\r\\nwhere ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57649</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Heartsong</td>\n",
       "      <td>/z/zwan/heartsong_20148991.html</td>\n",
       "      <td>come in  \\r\\nmake yourself at home  \\r\\ni'm a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57650 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist                   song  \\\n",
       "0              ABBA  Ahe's My Kind Of Girl   \n",
       "1              ABBA       Andante, Andante   \n",
       "2              ABBA         As Good As New   \n",
       "3              ABBA                   Bang   \n",
       "4              ABBA       Bang-A-Boomerang   \n",
       "...             ...                    ...   \n",
       "57645  Ziggy Marley          Good Old Days   \n",
       "57646  Ziggy Marley          Hand To Mouth   \n",
       "57647          Zwan           Come With Me   \n",
       "57648          Zwan                 Desire   \n",
       "57649          Zwan              Heartsong   \n",
       "\n",
       "                                              link  \\\n",
       "0       /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1            /a/abba/andante+andante_20002708.html   \n",
       "2             /a/abba/as+good+as+new_20003033.html   \n",
       "3                       /a/abba/bang_20598415.html   \n",
       "4           /a/abba/bang+a+boomerang_20002668.html   \n",
       "...                                            ...   \n",
       "57645  /z/ziggy+marley/good+old+days_10198588.html   \n",
       "57646  /z/ziggy+marley/hand+to+mouth_20531167.html   \n",
       "57647           /z/zwan/come+with+me_20148981.html   \n",
       "57648                 /z/zwan/desire_20148986.html   \n",
       "57649              /z/zwan/heartsong_20148991.html   \n",
       "\n",
       "                                                    text  \n",
       "0      Look at her face, it's a wonderful face  \\r\\nA...  \n",
       "1      Take it easy with me, please  \\r\\nTouch me gen...  \n",
       "2      I'll never know why I had to go  \\r\\nWhy I had...  \n",
       "3      Making somebody happy is a question of give an...  \n",
       "4      Making somebody happy is a question of give an...  \n",
       "...                                                  ...  \n",
       "57645  Irie days come on play  \\r\\nLet the angels fly...  \n",
       "57646  Power to the workers  \\r\\nMore power  \\r\\nPowe...  \n",
       "57647  all you need  \\r\\nis something i'll believe  \\...  \n",
       "57648  northern star  \\r\\nam i frightened  \\r\\nwhere ...  \n",
       "57649  come in  \\r\\nmake yourself at home  \\r\\ni'm a ...  \n",
       "\n",
       "[57650 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:01:52.445007Z",
     "iopub.status.busy": "2026-01-30T10:01:52.444468Z",
     "iopub.status.idle": "2026-01-30T10:01:52.457949Z",
     "shell.execute_reply": "2026-01-30T10:01:52.457171Z",
     "shell.execute_reply.started": "2026-01-30T10:01:52.444982Z"
    },
    "id": "lVo1-LeBeCx2",
    "outputId": "23530393-3b16-4bec-ac03-b275765c3862"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:01:52.459095Z",
     "iopub.status.busy": "2026-01-30T10:01:52.45885Z",
     "iopub.status.idle": "2026-01-30T10:01:52.485148Z",
     "shell.execute_reply": "2026-01-30T10:01:52.484341Z",
     "shell.execute_reply.started": "2026-01-30T10:01:52.459075Z"
    },
    "id": "C7Z5rSOGeCx3",
    "outputId": "f60792ae-c77d-47b2-d4dc-4a49cae60f84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44824"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['song'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:01:52.486334Z",
     "iopub.status.busy": "2026-01-30T10:01:52.486027Z",
     "iopub.status.idle": "2026-01-30T10:01:52.493733Z",
     "shell.execute_reply": "2026-01-30T10:01:52.492878Z",
     "shell.execute_reply.started": "2026-01-30T10:01:52.486303Z"
    },
    "id": "4_1qH1UJeCx3",
    "outputId": "501e6719-2575-42fa-ecf9-9bb5df4d6321"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Look at her face, it's a wonderful face  \\r\\nA...\n",
       "1    Take it easy with me, please  \\r\\nTouch me gen...\n",
       "2    I'll never know why I had to go  \\r\\nWhy I had...\n",
       "3    Making somebody happy is a question of give an...\n",
       "4    Making somebody happy is a question of give an...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:01:52.495159Z",
     "iopub.status.busy": "2026-01-30T10:01:52.494897Z",
     "iopub.status.idle": "2026-01-30T10:01:52.514422Z",
     "shell.execute_reply": "2026-01-30T10:01:52.513456Z",
     "shell.execute_reply.started": "2026-01-30T10:01:52.495137Z"
    },
    "id": "8DovhUwXeCx3"
   },
   "outputs": [],
   "source": [
    "df_text = df[['text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:02:28.135825Z",
     "iopub.status.busy": "2026-01-30T10:02:28.134875Z",
     "iopub.status.idle": "2026-01-30T10:02:34.024859Z",
     "shell.execute_reply": "2026-01-30T10:02:34.023847Z",
     "shell.execute_reply.started": "2026-01-30T10:02:28.135775Z"
    },
    "id": "-dlOEn8BeCx5",
    "outputId": "e1ad970a-4bad-47ad-f4cb-adc4f442d377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\enter store\\anaconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:02:34.026971Z",
     "iopub.status.busy": "2026-01-30T10:02:34.026658Z",
     "iopub.status.idle": "2026-01-30T10:02:39.067684Z",
     "shell.execute_reply": "2026-01-30T10:02:39.066822Z",
     "shell.execute_reply.started": "2026-01-30T10:02:34.026942Z"
    },
    "id": "aOw2ZbMEeCx6"
   },
   "outputs": [],
   "source": [
    "import contractions\n",
    "\n",
    "def expand_contractions_lib(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "df_text['text'] = df_text['text'].apply(lambda x: contractions.fix(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:02:39.06866Z",
     "iopub.status.busy": "2026-01-30T10:02:39.068454Z",
     "iopub.status.idle": "2026-01-30T10:02:40.534574Z",
     "shell.execute_reply": "2026-01-30T10:02:40.533742Z",
     "shell.execute_reply.started": "2026-01-30T10:02:39.068638Z"
    },
    "id": "sgntUMKReCx6",
    "outputId": "cbaa509a-5f86-4a63-e0d6-b6ca678a5f41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Enter\n",
      "[nltk_data]     Store\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Enter\n",
      "[nltk_data]     Store\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:02:40.536318Z",
     "iopub.status.busy": "2026-01-30T10:02:40.535962Z",
     "iopub.status.idle": "2026-01-30T10:03:00.629611Z",
     "shell.execute_reply": "2026-01-30T10:03:00.628729Z",
     "shell.execute_reply.started": "2026-01-30T10:02:40.536298Z"
    },
    "id": "S_EycYiLeCx6",
    "outputId": "89b92d7f-4382-47b3-b61c-d513f73e15ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: Cleaning Text ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 57650/57650 [00:20<00:00, 2751.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning completed. Sample:\n",
      "0    look face wonderful face means something speci...\n",
      "1    take easy please touch gently like summer even...\n",
      "2    never know go put lousy rotten show boy tough ...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "#from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCTION 1: TEXT CLEANING\n",
    "# ============================================================================\n",
    "\n",
    "def clean_text(text, spell_correct=False, remove_stopwords=True):\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+|https\\S+', '', text)\n",
    "\n",
    "    # 3. Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "    # 3. REMOVE datetime FIRST ✅\n",
    "    text = re.sub(\n",
    "        r'on\\s+\\w+,\\s+\\d{4}-\\d{2}-\\d{2}\\s+at\\s+\\d{1,2}:\\d{2}',\n",
    "        '',\n",
    "        text,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # 4. Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # 5. Remove mentions (@username)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    # 6. Remove hashtags (#hashtag)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "\n",
    "    # 7. Remove repeated characters (heeeello -> helo)\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "\n",
    "    # 8. Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # 9. Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # 10. Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    # 11. Tokenize\n",
    "    tokens = text.split()\n",
    "\n",
    "    # 12. Remove stopwords (optional)\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        tokens = [w for w in tokens if w not in stop_words and len(w) >= 2]\n",
    "    else:\n",
    "        # Just filter short words\n",
    "        tokens = [w for w in tokens if len(w) >= 2]\n",
    "    \"\"\"\n",
    "    # 13. Spell correction (optional and SLOW)\n",
    "    if spell_correct:\n",
    "        tokens = [str(TextBlob(w).correct()) for w in tokens]\n",
    "    \"\"\"\n",
    "\n",
    "    # Return cleaned tokens as string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "# Step 1: Clean the text\n",
    "print(\"=== Step 1: Cleaning Text ===\")\n",
    "df_text['cleaned_text'] = df_text['text'].progress_apply(\n",
    "    lambda x: clean_text(x, spell_correct=False, remove_stopwords=True)\n",
    ")\n",
    "\n",
    "print(f\"Cleaning completed. Sample:\\n{df_text['cleaned_text'].head(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:03:00.631132Z",
     "iopub.status.busy": "2026-01-30T10:03:00.630884Z",
     "iopub.status.idle": "2026-01-30T10:03:00.640505Z",
     "shell.execute_reply": "2026-01-30T10:03:00.63985Z",
     "shell.execute_reply.started": "2026-01-30T10:03:00.631113Z"
    },
    "id": "lAkydY2jeCx7",
    "outputId": "d76ef0e9-6ebb-449d-dd4d-79f9e7b314d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Look at her face, it is a wonderful face  \\r\\n...</td>\n",
       "      <td>look face wonderful face means something speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "      <td>take easy please touch gently like summer even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I will never know why I had to go  \\r\\nWhy I h...</td>\n",
       "      <td>never know go put lousy rotten show boy tough ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>making somebody happy question give take learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>making somebody happy question give take learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57645</th>\n",
       "      <td>Irie days come on play  \\r\\nLet the angels fly...</td>\n",
       "      <td>irie days come play let angels fly let devils ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57646</th>\n",
       "      <td>Power to the workers  \\r\\nMore power  \\r\\nPowe...</td>\n",
       "      <td>power workers power power workers need power p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57647</th>\n",
       "      <td>all you need  \\r\\nis something i will believe ...</td>\n",
       "      <td>need something believe flashlights hall call d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57648</th>\n",
       "      <td>northern star  \\r\\nam i frightened  \\r\\nwhere ...</td>\n",
       "      <td>northern star frightened go rest cannot sleep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57649</th>\n",
       "      <td>come in  \\r\\nmake yourself at home  \\r\\ni am a...</td>\n",
       "      <td>come make home bit late hate make wait heart s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57650 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Look at her face, it is a wonderful face  \\r\\n...   \n",
       "1      Take it easy with me, please  \\r\\nTouch me gen...   \n",
       "2      I will never know why I had to go  \\r\\nWhy I h...   \n",
       "3      Making somebody happy is a question of give an...   \n",
       "4      Making somebody happy is a question of give an...   \n",
       "...                                                  ...   \n",
       "57645  Irie days come on play  \\r\\nLet the angels fly...   \n",
       "57646  Power to the workers  \\r\\nMore power  \\r\\nPowe...   \n",
       "57647  all you need  \\r\\nis something i will believe ...   \n",
       "57648  northern star  \\r\\nam i frightened  \\r\\nwhere ...   \n",
       "57649  come in  \\r\\nmake yourself at home  \\r\\ni am a...   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0      look face wonderful face means something speci...  \n",
       "1      take easy please touch gently like summer even...  \n",
       "2      never know go put lousy rotten show boy tough ...  \n",
       "3      making somebody happy question give take learn...  \n",
       "4      making somebody happy question give take learn...  \n",
       "...                                                  ...  \n",
       "57645  irie days come play let angels fly let devils ...  \n",
       "57646  power workers power power workers need power p...  \n",
       "57647  need something believe flashlights hall call d...  \n",
       "57648  northern star frightened go rest cannot sleep ...  \n",
       "57649  come make home bit late hate make wait heart s...  \n",
       "\n",
       "[57650 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:03:08.825923Z",
     "iopub.status.busy": "2026-01-30T10:03:08.825535Z",
     "iopub.status.idle": "2026-01-30T10:03:38.975256Z",
     "shell.execute_reply": "2026-01-30T10:03:38.974378Z",
     "shell.execute_reply.started": "2026-01-30T10:03:08.825896Z"
    },
    "id": "m4v24PvUeCx7",
    "outputId": "52173d31-2257-4e19-9179-3ad00afc0163"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 57650/57650 [00:20<00:00, 2773.53it/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_text(text):\n",
    "  word_token = nltk.word_tokenize(text)\n",
    "  sentance_token = nltk.sent_tokenize(text)\n",
    "\n",
    "  return word_token , sentance_token\n",
    "\n",
    "df_text[['word_tokens', 'sentence_tokens']] = df_text['cleaned_text'].progress_apply(\n",
    "    lambda x: pd.Series(tokenize_text(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\enter store\\anaconda3\\lib\\site-packages (4.57.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "434a2f259611489ea6c691888472b33f",
      "4e32bd4f5c7644c6b4aa868100a6c109",
      "36d20a0354e34de2b6056f8dbb4fdd1a",
      "06ded72a8c2e45729578b535533dbd4c"
     ]
    },
    "execution": {
     "iopub.execute_input": "2026-01-30T10:03:38.980805Z",
     "iopub.status.busy": "2026-01-30T10:03:38.980483Z",
     "iopub.status.idle": "2026-01-30T10:04:30.909618Z",
     "shell.execute_reply": "2026-01-30T10:04:30.908752Z",
     "shell.execute_reply.started": "2026-01-30T10:03:38.980767Z"
    },
    "id": "5fH9_c95eCx7",
    "outputId": "f5f8ae0f-2394-4e9e-f3f5-0ee357ebae17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 57650/57650 [00:21<00:00, 2707.05it/s]\n"
     ]
    }
   ],
   "source": [
    "#tokenization\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\"\"\"\n",
    "df_text['token_word_tokenization'] = df_text['word_tokens'].progress_apply(\n",
    "    lambda x: tokenizer.tokenize(' '.join(x)) if isinstance(x, list) else []\n",
    ")\"\"\"\n",
    "\n",
    "df_text['bert_inputs'] = df_text['word_tokens'].progress_apply(\n",
    "    lambda x: tokenizer(\n",
    "        ' '.join(x),\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512,\n",
    "        return_tensors=None\n",
    "    ) if isinstance(x, list) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:04:30.911421Z",
     "iopub.status.busy": "2026-01-30T10:04:30.911011Z",
     "iopub.status.idle": "2026-01-30T10:04:30.932438Z",
     "shell.execute_reply": "2026-01-30T10:04:30.931501Z",
     "shell.execute_reply.started": "2026-01-30T10:04:30.911402Z"
    },
    "id": "4ovzzVD2eCx7",
    "outputId": "a2c5b0f7-122a-42bc-c404-a337af540898"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>bert_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Look at her face, it is a wonderful face  \\r\\n...</td>\n",
       "      <td>look face wonderful face means something speci...</td>\n",
       "      <td>[look, face, wonderful, face, means, something...</td>\n",
       "      <td>[look face wonderful face means something spec...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "      <td>take easy please touch gently like summer even...</td>\n",
       "      <td>[take, easy, please, touch, gently, like, summ...</td>\n",
       "      <td>[take easy please touch gently like summer eve...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I will never know why I had to go  \\r\\nWhy I h...</td>\n",
       "      <td>never know go put lousy rotten show boy tough ...</td>\n",
       "      <td>[never, know, go, put, lousy, rotten, show, bo...</td>\n",
       "      <td>[never know go put lousy rotten show boy tough...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>making somebody happy question give take learn...</td>\n",
       "      <td>[making, somebody, happy, question, give, take...</td>\n",
       "      <td>[making somebody happy question give take lear...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>making somebody happy question give take learn...</td>\n",
       "      <td>[making, somebody, happy, question, give, take...</td>\n",
       "      <td>[making somebody happy question give take lear...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57645</th>\n",
       "      <td>Irie days come on play  \\r\\nLet the angels fly...</td>\n",
       "      <td>irie days come play let angels fly let devils ...</td>\n",
       "      <td>[irie, days, come, play, let, angels, fly, let...</td>\n",
       "      <td>[irie days come play let angels fly let devils...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57646</th>\n",
       "      <td>Power to the workers  \\r\\nMore power  \\r\\nPowe...</td>\n",
       "      <td>power workers power power workers need power p...</td>\n",
       "      <td>[power, workers, power, power, workers, need, ...</td>\n",
       "      <td>[power workers power power workers need power ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57647</th>\n",
       "      <td>all you need  \\r\\nis something i will believe ...</td>\n",
       "      <td>need something believe flashlights hall call d...</td>\n",
       "      <td>[need, something, believe, flashlights, hall, ...</td>\n",
       "      <td>[need something believe flashlights hall call ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57648</th>\n",
       "      <td>northern star  \\r\\nam i frightened  \\r\\nwhere ...</td>\n",
       "      <td>northern star frightened go rest cannot sleep ...</td>\n",
       "      <td>[northern, star, frightened, go, rest, can, no...</td>\n",
       "      <td>[northern star frightened go rest cannot sleep...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57649</th>\n",
       "      <td>come in  \\r\\nmake yourself at home  \\r\\ni am a...</td>\n",
       "      <td>come make home bit late hate make wait heart s...</td>\n",
       "      <td>[come, make, home, bit, late, hate, make, wait...</td>\n",
       "      <td>[come make home bit late hate make wait heart ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57650 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Look at her face, it is a wonderful face  \\r\\n...   \n",
       "1      Take it easy with me, please  \\r\\nTouch me gen...   \n",
       "2      I will never know why I had to go  \\r\\nWhy I h...   \n",
       "3      Making somebody happy is a question of give an...   \n",
       "4      Making somebody happy is a question of give an...   \n",
       "...                                                  ...   \n",
       "57645  Irie days come on play  \\r\\nLet the angels fly...   \n",
       "57646  Power to the workers  \\r\\nMore power  \\r\\nPowe...   \n",
       "57647  all you need  \\r\\nis something i will believe ...   \n",
       "57648  northern star  \\r\\nam i frightened  \\r\\nwhere ...   \n",
       "57649  come in  \\r\\nmake yourself at home  \\r\\ni am a...   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "0      look face wonderful face means something speci...   \n",
       "1      take easy please touch gently like summer even...   \n",
       "2      never know go put lousy rotten show boy tough ...   \n",
       "3      making somebody happy question give take learn...   \n",
       "4      making somebody happy question give take learn...   \n",
       "...                                                  ...   \n",
       "57645  irie days come play let angels fly let devils ...   \n",
       "57646  power workers power power workers need power p...   \n",
       "57647  need something believe flashlights hall call d...   \n",
       "57648  northern star frightened go rest cannot sleep ...   \n",
       "57649  come make home bit late hate make wait heart s...   \n",
       "\n",
       "                                             word_tokens  \\\n",
       "0      [look, face, wonderful, face, means, something...   \n",
       "1      [take, easy, please, touch, gently, like, summ...   \n",
       "2      [never, know, go, put, lousy, rotten, show, bo...   \n",
       "3      [making, somebody, happy, question, give, take...   \n",
       "4      [making, somebody, happy, question, give, take...   \n",
       "...                                                  ...   \n",
       "57645  [irie, days, come, play, let, angels, fly, let...   \n",
       "57646  [power, workers, power, power, workers, need, ...   \n",
       "57647  [need, something, believe, flashlights, hall, ...   \n",
       "57648  [northern, star, frightened, go, rest, can, no...   \n",
       "57649  [come, make, home, bit, late, hate, make, wait...   \n",
       "\n",
       "                                         sentence_tokens  \\\n",
       "0      [look face wonderful face means something spec...   \n",
       "1      [take easy please touch gently like summer eve...   \n",
       "2      [never know go put lousy rotten show boy tough...   \n",
       "3      [making somebody happy question give take lear...   \n",
       "4      [making somebody happy question give take lear...   \n",
       "...                                                  ...   \n",
       "57645  [irie days come play let angels fly let devils...   \n",
       "57646  [power workers power power workers need power ...   \n",
       "57647  [need something believe flashlights hall call ...   \n",
       "57648  [northern star frightened go rest cannot sleep...   \n",
       "57649  [come make home bit late hate make wait heart ...   \n",
       "\n",
       "                                       bert_inputs  \n",
       "0      [input_ids, token_type_ids, attention_mask]  \n",
       "1      [input_ids, token_type_ids, attention_mask]  \n",
       "2      [input_ids, token_type_ids, attention_mask]  \n",
       "3      [input_ids, token_type_ids, attention_mask]  \n",
       "4      [input_ids, token_type_ids, attention_mask]  \n",
       "...                                            ...  \n",
       "57645  [input_ids, token_type_ids, attention_mask]  \n",
       "57646  [input_ids, token_type_ids, attention_mask]  \n",
       "57647  [input_ids, token_type_ids, attention_mask]  \n",
       "57648  [input_ids, token_type_ids, attention_mask]  \n",
       "57649  [input_ids, token_type_ids, attention_mask]  \n",
       "\n",
       "[57650 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:04:30.933709Z",
     "iopub.status.busy": "2026-01-30T10:04:30.933368Z",
     "iopub.status.idle": "2026-01-30T10:04:31.086121Z",
     "shell.execute_reply": "2026-01-30T10:04:31.084948Z",
     "shell.execute_reply.started": "2026-01-30T10:04:30.933662Z"
    },
    "id": "6EEBerOUeCx7"
   },
   "outputs": [],
   "source": [
    "df_text['input_ids'] = df_text['bert_inputs'].apply(lambda x: x['input_ids'])\n",
    "df_text['attention_mask'] = df_text['bert_inputs'].apply(lambda x: x['attention_mask'])\n",
    "df_text['token_type_ids'] = df_text['bert_inputs'].apply(lambda x: x['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:04:31.088111Z",
     "iopub.status.busy": "2026-01-30T10:04:31.087771Z",
     "iopub.status.idle": "2026-01-30T10:04:31.129062Z",
     "shell.execute_reply": "2026-01-30T10:04:31.128073Z",
     "shell.execute_reply.started": "2026-01-30T10:04:31.088086Z"
    },
    "id": "K73vkV9deCx8",
    "outputId": "753ec3da-a7a2-48ee-bd75-53b370fb09c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sentence_tokens</th>\n",
       "      <th>bert_inputs</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Look at her face, it is a wonderful face  \\r\\n...</td>\n",
       "      <td>look face wonderful face means something speci...</td>\n",
       "      <td>[look, face, wonderful, face, means, something...</td>\n",
       "      <td>[look face wonderful face means something spec...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[101, 2298, 2227, 6919, 2227, 2965, 2242, 2569...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "      <td>take easy please touch gently like summer even...</td>\n",
       "      <td>[take, easy, please, touch, gently, like, summ...</td>\n",
       "      <td>[take easy please touch gently like summer eve...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[101, 2202, 3733, 3531, 3543, 5251, 2066, 2621...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I will never know why I had to go  \\r\\nWhy I h...</td>\n",
       "      <td>never know go put lousy rotten show boy tough ...</td>\n",
       "      <td>[never, know, go, put, lousy, rotten, show, bo...</td>\n",
       "      <td>[never know go put lousy rotten show boy tough...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[101, 2196, 2113, 2175, 2404, 10223, 6508, 110...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>making somebody happy question give take learn...</td>\n",
       "      <td>[making, somebody, happy, question, give, take...</td>\n",
       "      <td>[making somebody happy question give take lear...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[101, 2437, 8307, 3407, 3160, 2507, 2202, 4553...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "      <td>making somebody happy question give take learn...</td>\n",
       "      <td>[making, somebody, happy, question, give, take...</td>\n",
       "      <td>[making somebody happy question give take lear...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[101, 2437, 8307, 3407, 3160, 2507, 2202, 4553...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57645</th>\n",
       "      <td>Irie days come on play  \\r\\nLet the angels fly...</td>\n",
       "      <td>irie days come play let angels fly let devils ...</td>\n",
       "      <td>[irie, days, come, play, let, angels, fly, let...</td>\n",
       "      <td>[irie days come play let angels fly let devils...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[101, 20868, 2666, 2420, 2272, 2377, 2292, 704...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57646</th>\n",
       "      <td>Power to the workers  \\r\\nMore power  \\r\\nPowe...</td>\n",
       "      <td>power workers power power workers need power p...</td>\n",
       "      <td>[power, workers, power, power, workers, need, ...</td>\n",
       "      <td>[power workers power power workers need power ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[101, 2373, 3667, 2373, 2373, 3667, 2342, 2373...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57647</th>\n",
       "      <td>all you need  \\r\\nis something i will believe ...</td>\n",
       "      <td>need something believe flashlights hall call d...</td>\n",
       "      <td>[need, something, believe, flashlights, hall, ...</td>\n",
       "      <td>[need something believe flashlights hall call ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[101, 2342, 2242, 2903, 15257, 2015, 2534, 265...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57648</th>\n",
       "      <td>northern star  \\r\\nam i frightened  \\r\\nwhere ...</td>\n",
       "      <td>northern star frightened go rest cannot sleep ...</td>\n",
       "      <td>[northern, star, frightened, go, rest, can, no...</td>\n",
       "      <td>[northern star frightened go rest cannot sleep...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[101, 2642, 2732, 10363, 2175, 2717, 2064, 202...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57649</th>\n",
       "      <td>come in  \\r\\nmake yourself at home  \\r\\ni am a...</td>\n",
       "      <td>come make home bit late hate make wait heart s...</td>\n",
       "      <td>[come, make, home, bit, late, hate, make, wait...</td>\n",
       "      <td>[come make home bit late hate make wait heart ...</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[101, 2272, 2191, 2188, 2978, 2397, 5223, 2191...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57650 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Look at her face, it is a wonderful face  \\r\\n...   \n",
       "1      Take it easy with me, please  \\r\\nTouch me gen...   \n",
       "2      I will never know why I had to go  \\r\\nWhy I h...   \n",
       "3      Making somebody happy is a question of give an...   \n",
       "4      Making somebody happy is a question of give an...   \n",
       "...                                                  ...   \n",
       "57645  Irie days come on play  \\r\\nLet the angels fly...   \n",
       "57646  Power to the workers  \\r\\nMore power  \\r\\nPowe...   \n",
       "57647  all you need  \\r\\nis something i will believe ...   \n",
       "57648  northern star  \\r\\nam i frightened  \\r\\nwhere ...   \n",
       "57649  come in  \\r\\nmake yourself at home  \\r\\ni am a...   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "0      look face wonderful face means something speci...   \n",
       "1      take easy please touch gently like summer even...   \n",
       "2      never know go put lousy rotten show boy tough ...   \n",
       "3      making somebody happy question give take learn...   \n",
       "4      making somebody happy question give take learn...   \n",
       "...                                                  ...   \n",
       "57645  irie days come play let angels fly let devils ...   \n",
       "57646  power workers power power workers need power p...   \n",
       "57647  need something believe flashlights hall call d...   \n",
       "57648  northern star frightened go rest cannot sleep ...   \n",
       "57649  come make home bit late hate make wait heart s...   \n",
       "\n",
       "                                             word_tokens  \\\n",
       "0      [look, face, wonderful, face, means, something...   \n",
       "1      [take, easy, please, touch, gently, like, summ...   \n",
       "2      [never, know, go, put, lousy, rotten, show, bo...   \n",
       "3      [making, somebody, happy, question, give, take...   \n",
       "4      [making, somebody, happy, question, give, take...   \n",
       "...                                                  ...   \n",
       "57645  [irie, days, come, play, let, angels, fly, let...   \n",
       "57646  [power, workers, power, power, workers, need, ...   \n",
       "57647  [need, something, believe, flashlights, hall, ...   \n",
       "57648  [northern, star, frightened, go, rest, can, no...   \n",
       "57649  [come, make, home, bit, late, hate, make, wait...   \n",
       "\n",
       "                                         sentence_tokens  \\\n",
       "0      [look face wonderful face means something spec...   \n",
       "1      [take easy please touch gently like summer eve...   \n",
       "2      [never know go put lousy rotten show boy tough...   \n",
       "3      [making somebody happy question give take lear...   \n",
       "4      [making somebody happy question give take lear...   \n",
       "...                                                  ...   \n",
       "57645  [irie days come play let angels fly let devils...   \n",
       "57646  [power workers power power workers need power ...   \n",
       "57647  [need something believe flashlights hall call ...   \n",
       "57648  [northern star frightened go rest cannot sleep...   \n",
       "57649  [come make home bit late hate make wait heart ...   \n",
       "\n",
       "                                       bert_inputs  \\\n",
       "0      [input_ids, token_type_ids, attention_mask]   \n",
       "1      [input_ids, token_type_ids, attention_mask]   \n",
       "2      [input_ids, token_type_ids, attention_mask]   \n",
       "3      [input_ids, token_type_ids, attention_mask]   \n",
       "4      [input_ids, token_type_ids, attention_mask]   \n",
       "...                                            ...   \n",
       "57645  [input_ids, token_type_ids, attention_mask]   \n",
       "57646  [input_ids, token_type_ids, attention_mask]   \n",
       "57647  [input_ids, token_type_ids, attention_mask]   \n",
       "57648  [input_ids, token_type_ids, attention_mask]   \n",
       "57649  [input_ids, token_type_ids, attention_mask]   \n",
       "\n",
       "                                               input_ids  \\\n",
       "0      [101, 2298, 2227, 6919, 2227, 2965, 2242, 2569...   \n",
       "1      [101, 2202, 3733, 3531, 3543, 5251, 2066, 2621...   \n",
       "2      [101, 2196, 2113, 2175, 2404, 10223, 6508, 110...   \n",
       "3      [101, 2437, 8307, 3407, 3160, 2507, 2202, 4553...   \n",
       "4      [101, 2437, 8307, 3407, 3160, 2507, 2202, 4553...   \n",
       "...                                                  ...   \n",
       "57645  [101, 20868, 2666, 2420, 2272, 2377, 2292, 704...   \n",
       "57646  [101, 2373, 3667, 2373, 2373, 3667, 2342, 2373...   \n",
       "57647  [101, 2342, 2242, 2903, 15257, 2015, 2534, 265...   \n",
       "57648  [101, 2642, 2732, 10363, 2175, 2717, 2064, 202...   \n",
       "57649  [101, 2272, 2191, 2188, 2978, 2397, 5223, 2191...   \n",
       "\n",
       "                                          attention_mask  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                  ...   \n",
       "57645  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "57646  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "57647  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "57648  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "57649  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                          token_type_ids  \n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "57645  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "57646  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "57647  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "57648  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "57649  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[57650 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\enter store\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\enter store\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\enter store\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\enter store\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\enter store\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\enter store\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\enter store\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\enter store\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\enter store\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Enter Store\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\Enter' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'C:\\Users\\Enter' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "5e9bbbcfc96d4ac99276cff464db0a47"
     ]
    },
    "execution": {
     "iopub.execute_input": "2026-01-30T10:11:21.593852Z",
     "iopub.status.busy": "2026-01-30T10:11:21.593462Z",
     "iopub.status.idle": "2026-01-30T10:11:57.60098Z",
     "shell.execute_reply": "2026-01-30T10:11:57.600199Z",
     "shell.execute_reply.started": "2026-01-30T10:11:21.593822Z"
    },
    "id": "_PzBqEPbeCx8",
    "outputId": "387fb14c-e913-4afb-bed6-cbd88b587286"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T10:12:18.210489Z",
     "iopub.status.busy": "2026-01-30T10:12:18.20995Z"
    },
    "id": "gjz-G-MgeCx8",
    "outputId": "fc44f40a-8402-4e07-8fa3-1b4043420b09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\nfrom tqdm import tqdm\\n\\ndef get_embedding(text):\\n    inputs = tokenizer(\\n        text,\\n        truncation=True,\\n        padding=\"max_length\",\\n        max_length=256,   # 512 is overkill for lyrics\\n        return_tensors=\"pt\"\\n    )\\n    inputs = {k: v.to(device) for k, v in inputs.items()}\\n\\n    with torch.no_grad():\\n        outputs = model(**inputs)\\n\\n    # CLS token embedding\\n    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze()\\n    return cls_embedding.cpu().numpy()\\n\\ndf[\\'embedding\\'] = [\\n    get_embedding(text) for text in tqdm(df[\\'text\\'], desc=\"Embedding songs\")\\n]\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,   # 512 is overkill for lyrics\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # CLS token embedding\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze()\n",
    "    return cls_embedding.cpu().numpy()\n",
    "\n",
    "df['embedding'] = [\n",
    "    get_embedding(text) for text in tqdm(df['text'], desc=\"Embedding songs\")\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport torch\\nimport numpy as np\\nfrom tqdm.auto import tqdm\\n\\ndef embed_texts(texts, batch_size=32):\\n    all_embeddings = []\\n\\n    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding songs\"):\\n        batch_texts = texts[i:i+batch_size]\\n\\n        inputs = tokenizer(\\n            batch_texts,\\n            truncation=True,\\n            padding=True,        # dynamic padding\\n            max_length=256,\\n            return_tensors=\"pt\"\\n        )\\n\\n        inputs = {k: v.to(device) for k, v in inputs.items()}\\n\\n        with torch.no_grad():\\n            outputs = model(**inputs)\\n\\n        cls_embeddings = outputs.last_hidden_state[:, 0, :]\\n\\n        all_embeddings.append(cls_embeddings.cpu().numpy())\\n\\n        # 🔥 free GPU memory explicitly\\n        del inputs, outputs, cls_embeddings\\n        torch.cuda.empty_cache()\\n\\n    return np.vstack(all_embeddings)\\n\\ndf[\\'embedding\\'] = list(embed_texts(df[\\'text\\'].tolist(), batch_size=16))\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def embed_texts(texts, batch_size=32):\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding songs\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            truncation=True,\n",
    "            padding=True,        # dynamic padding\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        all_embeddings.append(cls_embeddings.cpu().numpy())\n",
    "\n",
    "        # 🔥 free GPU memory explicitly\n",
    "        del inputs, outputs, cls_embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "df['embedding'] = list(embed_texts(df['text'].tolist(), batch_size=16))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from index 57664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding songs: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def embed_texts_safe(texts, batch_size=16, save_every=50, out_file=\"embeddings.pkl\"):\n",
    "    all_embeddings = []\n",
    "\n",
    "    # Resume if file exists\n",
    "    if os.path.exists(out_file):\n",
    "        with open(out_file, \"rb\") as f:\n",
    "            all_embeddings = pickle.load(f)\n",
    "        start_idx = len(all_embeddings) * batch_size\n",
    "        print(f\"Resuming from index {start_idx}\")\n",
    "    else:\n",
    "        start_idx = 0\n",
    "\n",
    "    for i in tqdm(range(start_idx, len(texts), batch_size), desc=\"Embedding songs\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        all_embeddings.append(cls_embeddings)\n",
    "\n",
    "        # Save every N batches\n",
    "        if len(all_embeddings) % save_every == 0:\n",
    "            with open(out_file, \"wb\") as f:\n",
    "                pickle.dump(all_embeddings, f)\n",
    "\n",
    "        del inputs, outputs, cls_embeddings\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Final save\n",
    "    with open(out_file, \"wb\") as f:\n",
    "        pickle.dump(all_embeddings, f)\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "df['embedding'] = list(\n",
    "    embed_texts_safe(df['text'].tolist(), batch_size=16)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "dBRbwfAaeCx8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embeddings = np.vstack(df['embedding'])\n",
    "\n",
    "similarity_matrix = cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "a7jXK0R2eCx8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8634</th>\n",
       "      <td>INXS</td>\n",
       "      <td>Perfect Strangers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26696</th>\n",
       "      <td>Bryan White</td>\n",
       "      <td>The Natural Thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26575</th>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>Hearts Of Stone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13104</th>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>Been Here All Along</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29445</th>\n",
       "      <td>Demi Lovato</td>\n",
       "      <td>Kiss Me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist                 song\n",
       "8634                INXS    Perfect Strangers\n",
       "26696        Bryan White    The Natural Thing\n",
       "26575  Bruce Springsteen      Hearts Of Stone\n",
       "13104        Miley Cyrus  Been Here All Along\n",
       "29445        Demi Lovato              Kiss Me"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_songs(song_index, top_k=5):\n",
    "    song_vector = embeddings[song_index].reshape(1, -1)\n",
    "    sims = cosine_similarity(song_vector, embeddings)[0]\n",
    "\n",
    "    similar_indices = sims.argsort()[::-1][1:top_k+1]\n",
    "\n",
    "    return df.iloc[similar_indices][['artist', 'song']]\n",
    "\n",
    "recommend_songs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embedding'] = list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\enter store\\anaconda3\\lib\\site-packages (5.1.2)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.57.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.9.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc867a0e8b94088a8149a1bc5d3d4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embeddings = model.encode(\n",
    "    df['text'].tolist(),\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True\n",
    ")\n",
    "\n",
    "df['embedding'] = list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdbscan in c:\\users\\enter store\\anaconda3\\lib\\site-packages (0.8.41)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from hdbscan) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from hdbscan) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from hdbscan) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from hdbscan) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\enter store\\anaconda3\\lib\\site-packages (from scikit-learn>=1.6->hdbscan) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\enter store\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=15,\n",
    "    metric='euclidean',\n",
    "    cluster_selection_method='eom'\n",
    ")\n",
    "\n",
    "df['cluster'] = clusterer.fit_predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, song]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['cluster'] == 3][['artist', 'song']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: ['baby' 'don' 'got' 'just' 'know' 'let' 'like' 'll' 'love' 'oh']\n",
      "Cluster 0: ['amore' 'che' 'di' 'il' 'la' 'mi' 'non' 'se' 'te' 'tu']\n",
      "Cluster 2: ['boy' 'bring' 'come' 'drum' 'king' 'pa' 'played' 'pom' 'pum' 'rum']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "for c in df['cluster'].unique():\n",
    "    if c == -1:\n",
    "        continue\n",
    "        \n",
    "    texts = df[df['cluster'] == c]['text']\n",
    "    tfidf = TfidfVectorizer(stop_words='english', max_features=10)\n",
    "    tfidf.fit(texts)\n",
    "    \n",
    "    print(f\"Cluster {c}: {tfidf.get_feature_names_out()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31545</th>\n",
       "      <td>Engelbert Humperdinck</td>\n",
       "      <td>Dancing With Tears In My Eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30081</th>\n",
       "      <td>Don McLean</td>\n",
       "      <td>Wonderful Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24662</th>\n",
       "      <td>Beach Boys</td>\n",
       "      <td>Isn't It Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18252</th>\n",
       "      <td>Roxy Music</td>\n",
       "      <td>Dance Away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26575</th>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>Hearts Of Stone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      artist                           song\n",
       "31545  Engelbert Humperdinck  Dancing With Tears In My Eyes\n",
       "30081             Don McLean                Wonderful Night\n",
       "24662             Beach Boys                  Isn't It Time\n",
       "18252             Roxy Music                     Dance Away\n",
       "26575      Bruce Springsteen                Hearts Of Stone"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_similar(song_idx, top_k=5):\n",
    "    cluster_id = df.loc[song_idx, 'cluster']\n",
    "    cluster_df = df[df['cluster'] == cluster_id]\n",
    "    \n",
    "    sims = cosine_similarity(\n",
    "        [df.loc[song_idx, 'embedding']],\n",
    "        np.vstack(cluster_df['embedding'])\n",
    "    )[0]\n",
    "    \n",
    "    top = sims.argsort()[::-1][1:top_k+1]\n",
    "    return cluster_df.iloc[top][['artist', 'song']]\n",
    "\n",
    "recommend_similar(song_idx=10, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55888</th>\n",
       "      <td>Weird Al Yankovic</td>\n",
       "      <td>Bohemian Polka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56828</th>\n",
       "      <td>X Japan</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49342</th>\n",
       "      <td>Queen</td>\n",
       "      <td>Mother Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002</th>\n",
       "      <td>Loretta Lynn</td>\n",
       "      <td>It'll Feel Good When It Quits Hurtin'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12765</th>\n",
       "      <td>Megadeth</td>\n",
       "      <td>Tornado Of Souls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist                                   song\n",
       "55888  Weird Al Yankovic                         Bohemian Polka\n",
       "56828            X Japan                                  Alive\n",
       "49342              Queen                            Mother Love\n",
       "12002       Loretta Lynn  It'll Feel Good When It Quits Hurtin'\n",
       "12765           Megadeth                       Tornado Of Souls"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_by_song_name(song_name, top_k=5):\n",
    "    idx = df[df['song'].str.lower() == song_name.lower()].index[0]\n",
    "    return recommend_similar(idx, top_k)\n",
    "\n",
    "recommend_by_song_name(\"Bohemian Rhapsody\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = {}\n",
    "\n",
    "for idx in df.index[:100]:\n",
    "    recommendations[idx] = recommend_similar(idx, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "song-dataset",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2660706,
     "sourceId": 4558658,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
